{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Notebook - Matt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import HelperFunctions as hf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in the raw data\n",
    "calendar_df = hf.load_calendar_data()\n",
    "prices_df = hf.load_sell_price_data()\n",
    "sales_df = hf.load_sales_train_validation_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean the raw data\n",
    "df = hf.rawToClean(sales_df, calendar_df, prices_df, days=1200, items=1000, dropNAPrices=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hf.priceDifference(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hf.rollingPriceDifference(df, windowsize=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hf.rollingMeanDemandFeature(df, windowSize=7, shift=1)#Mean of previous week\n",
    "df = hf.rollingMeanDemandFeature(df, windowSize=14, shift=1)\n",
    "df = hf.rollingMeanDemandFeature(df, windowSize=28, shift=1) #Mean of previous 28 days\n",
    "df = hf.rollingMeanDemandFeature(df, windowSize=7, shift=7)\n",
    "df = hf.rollingMeanDemandFeature(df, windowSize=7, shift=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hf.rollingStdDemandFeature(df, windowSize=7, shift=1)\n",
    "df = hf.rollingStdDemandFeature(df, windowSize=14, shift=1)\n",
    "df = hf.rollingStdDemandFeature(df, windowSize=28, shift=1)\n",
    "df = hf.rollingStdDemandFeature(df, windowSize=7, shift=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mattwear/GroupWork/AML/HelperFunctions.py:230: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  data = pd.concat([data, d])\n"
     ]
    }
   ],
   "source": [
    "df = hf.rollingMeanWeekday(df, weeks = 3, shift = 1) #mean of previous 3 weeks (for that particular weekday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hf.lagFeature(df, var='sold', lag=1) #Amount sold day before\n",
    "df = hf.lagFeature(df, var='sold', lag=7) #Amount sold a week before\n",
    "df = hf.lagFeature(df, var='sold', lag=14)\n",
    "df = hf.lagFeature(df, var='sold', lag=28) #Amount sold 28 days before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True) #Drop rows with NAs (as result of lagged features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#product_ids = df.id.copy()\n",
    "df.drop(['id'], axis=1, inplace=True) #Drop the id column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "d                    0\n",
       "sold                 0\n",
       "wday                 0\n",
       "month                0\n",
       "year                 0\n",
       "snap_CA              0\n",
       "snap_TX              0\n",
       "snap_WI              0\n",
       "sell_price           0\n",
       "Cultural             0\n",
       "National             0\n",
       "Religious            0\n",
       "Sporting             0\n",
       "NoEvent              0\n",
       "Christmas            0\n",
       "weekend              0\n",
       "midweek              0\n",
       "monfri               0\n",
       "FOODS_1              0\n",
       "FOODS_2              0\n",
       "FOODS_3              0\n",
       "HOBBIES_1            0\n",
       "HOBBIES_2            0\n",
       "HOUSEHOLD_1          0\n",
       "HOUSEHOLD_2          0\n",
       "FOODS                0\n",
       "HOBBIES              0\n",
       "HOUSEHOLD            0\n",
       "CA_1                 0\n",
       "CA_2                 0\n",
       "CA_3                 0\n",
       "CA_4                 0\n",
       "TX_1                 0\n",
       "TX_2                 0\n",
       "TX_3                 0\n",
       "WI_1                 0\n",
       "WI_2                 0\n",
       "WI_3                 0\n",
       "CA                   0\n",
       "TX                   0\n",
       "WI                   0\n",
       "price_diff           0\n",
       "price_increase       0\n",
       "price_decrease       0\n",
       "price_increase_7     0\n",
       "price_decrease_7     0\n",
       "rolling_mean_7_1     0\n",
       "rolling_mean_14_1    0\n",
       "rolling_mean_28_1    0\n",
       "rolling_mean_7_7     0\n",
       "rolling_mean_7_28    0\n",
       "rolling_std_7_1      0\n",
       "rolling_std_14_1     0\n",
       "rolling_std_28_1     0\n",
       "rolling_std_7_28     0\n",
       "sold_lag_1           0\n",
       "sold_lag_7           0\n",
       "sold_lag_14          0\n",
       "sold_lag_28          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(777490, 59)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['d', 'sold', 'wday', 'month', 'year', 'snap_CA', 'snap_TX', 'snap_WI',\n",
       "       'sell_price', 'Cultural', 'National', 'Religious', 'Sporting',\n",
       "       'NoEvent', 'Christmas', 'weekend', 'midweek', 'monfri', 'FOODS_1',\n",
       "       'FOODS_2', 'FOODS_3', 'HOBBIES_1', 'HOBBIES_2', 'HOUSEHOLD_1',\n",
       "       'HOUSEHOLD_2', 'FOODS', 'HOBBIES', 'HOUSEHOLD', 'CA_1', 'CA_2', 'CA_3',\n",
       "       'CA_4', 'TX_1', 'TX_2', 'TX_3', 'WI_1', 'WI_2', 'WI_3', 'CA', 'TX',\n",
       "       'WI', 'price_diff', 'rolling_mean_7_1', 'rolling_mean_14_1',\n",
       "       'rolling_mean_28_1', 'rolling_mean_7_7', 'rolling_mean_7_28',\n",
       "       'rolling_std_7_1', 'rolling_std_14_1', 'rolling_std_28_1',\n",
       "       'rolling_std_7_28', 'sold_lag_1', 'sold_lag_7', 'sold_lag_14',\n",
       "       'sold_lag_28'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "We also isolate the target variables from the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardise features\n",
    "cols_to_norm = ['d','wday','month','year','sell_price','rolling_mean_7_1','rolling_mean_14_1','rolling_mean_28_1','rolling_mean_7_7','rolling_mean_7_28','sold_lag_1',\n",
    "                'sold_lag_7','sold_lag_14','sold_lag_28','rolling_std_7_1','rolling_std_14_1','rolling_std_28_1',\n",
    "               'rolling_std_7_28','price_diff']\n",
    "\n",
    "df[cols_to_norm] = MinMaxScaler().fit_transform(df[cols_to_norm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolate features and target variable\n",
    "y = df.sold.values\n",
    "X_df = df.drop(['sold'], axis=1)\n",
    "X = X_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(621992, 58)\n",
      "(621992,)\n",
      "(155498, 58)\n",
      "(155498,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "The results of fitting a linear regression model on the data and analysing the feature's p-values raises some interesting findings. \n",
    "* Amongst the event related features only cultural and xmas are significant. As expected, Xmas is the most influential feature of them all.  \n",
    "* The LR also confirms our findings in analysis that weekend/monfri/midweek are all significant features for predicting sales volume. \n",
    "* CA_4 and CA_3 is the only store that is an insignificant predictor. Perhaps higher population in this area?\n",
    "* The mean of sold items in the week leading up is the second most influential feature.\n",
    "* More expensive items sell in lower quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   sold   R-squared:                       0.589\n",
      "Model:                            OLS   Adj. R-squared:                  0.589\n",
      "Method:                 Least Squares   F-statistic:                 3.067e+04\n",
      "Date:                Tue, 02 Mar 2021   Prob (F-statistic):               0.00\n",
      "Time:                        15:01:35   Log-Likelihood:            -1.7991e+06\n",
      "No. Observations:              771183   AIC:                         3.598e+06\n",
      "Df Residuals:                  771146   BIC:                         3.599e+06\n",
      "Df Model:                          36                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=====================================================================================\n",
      "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------------\n",
      "d                    -1.7272      0.785     -2.202      0.028      -3.265      -0.190\n",
      "wday                  0.1548      0.014     11.004      0.000       0.127       0.182\n",
      "month                 0.4699      0.225      2.091      0.037       0.029       0.910\n",
      "year                  1.5984      0.734      2.176      0.030       0.159       3.038\n",
      "snap_CA               0.0260      0.011      2.459      0.014       0.005       0.047\n",
      "snap_TX               0.0579      0.008      7.205      0.000       0.042       0.074\n",
      "snap_WI               0.0258      0.008      3.296      0.001       0.010       0.041\n",
      "sell_price           -0.2342      0.030     -7.855      0.000      -0.293      -0.176\n",
      "Cultural             -0.2313      0.058     -4.010      0.000      -0.344      -0.118\n",
      "National             -0.0962      0.064     -1.505      0.132      -0.222       0.029\n",
      "Religious            -0.0509      0.059     -0.868      0.385      -0.166       0.064\n",
      "Sporting             -0.1026      0.069     -1.479      0.139      -0.239       0.033\n",
      "NoEvent              -0.0520      0.061     -0.849      0.396      -0.172       0.068\n",
      "Christmas            -1.1563      0.059    -19.700      0.000      -1.271      -1.041\n",
      "weekend               0.2797      0.019     14.790      0.000       0.243       0.317\n",
      "midweek              -0.1837      0.018     -9.957      0.000      -0.220      -0.148\n",
      "monfri               -0.0869      0.019     -4.650      0.000      -0.124      -0.050\n",
      "FOODS_1              -0.0120      0.010     -1.214      0.225      -0.031       0.007\n",
      "FOODS_2              -0.0194      0.010     -2.029      0.042      -0.038      -0.001\n",
      "FOODS_3               0.0464      0.008      5.474      0.000       0.030       0.063\n",
      "HOBBIES_1             0.0236      0.011      2.095      0.036       0.002       0.046\n",
      "HOBBIES_2            -0.0325      0.013     -2.516      0.012      -0.058      -0.007\n",
      "HOUSEHOLD_1           0.0191      0.010      1.900      0.057      -0.001       0.039\n",
      "HOUSEHOLD_2          -0.0162      0.010     -1.635      0.102      -0.036       0.003\n",
      "FOODS                 0.0150      0.019      0.773      0.440      -0.023       0.053\n",
      "HOBBIES              -0.0089      0.018     -0.504      0.615      -0.043       0.026\n",
      "HOUSEHOLD             0.0029      0.017      0.167      0.867      -0.031       0.037\n",
      "CA_1                 -0.0053      0.009     -0.571      0.568      -0.024       0.013\n",
      "CA_2                 -0.0038      0.010     -0.395      0.693      -0.023       0.015\n",
      "CA_3                  0.0384      0.009      4.059      0.000       0.020       0.057\n",
      "CA_4                 -0.0207      0.009     -2.250      0.024      -0.039      -0.003\n",
      "TX_1                  0.0072      0.009      0.772      0.440      -0.011       0.025\n",
      "TX_2                  0.0011      0.009      0.115      0.908      -0.017       0.019\n",
      "TX_3                 -0.0007      0.009     -0.072      0.942      -0.018       0.017\n",
      "WI_1                 -0.0032      0.009     -0.345      0.730      -0.021       0.015\n",
      "WI_2                 -0.0044      0.010     -0.454      0.650      -0.023       0.014\n",
      "WI_3                  0.0004      0.010      0.044      0.965      -0.018       0.019\n",
      "CA                    0.0086      0.019      0.454      0.650      -0.028       0.045\n",
      "TX                    0.0076      0.018      0.430      0.667      -0.027       0.042\n",
      "WI                   -0.0071      0.018     -0.404      0.686      -0.042       0.028\n",
      "rolling_mean_7_1     28.3852      0.247    114.866      0.000      27.901      28.870\n",
      "rolling_mean_28_1    19.9098      0.171    116.210      0.000      19.574      20.246\n",
      "sold_lag_1           59.4524      0.496    119.827      0.000      58.480      60.425\n",
      "sold_lag_7            5.7242      0.498     11.500      0.000       4.749       6.700\n",
      "sold_lag_28          21.9978      0.442     49.768      0.000      21.131      22.864\n",
      "==============================================================================\n",
      "Omnibus:                  1515025.054   Durbin-Watson:                   2.000\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):      52788980626.329\n",
      "Skew:                          14.670   Prob(JB):                         0.00\n",
      "Kurtosis:                    1284.400   Cond. No.                     5.88e+15\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 8.17e-26. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "mod = sm.OLS(df['sold'], df[X_df.columns])\n",
    "#mod = sm.OLS(y_train, X_train)\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Train test split\n",
    "###Normalise features\n",
    "###More Data Analysis\n",
    "###Feature Extraction - average of weekday - exponential averages - Eve Events\n",
    "###Modelling\n",
    "###Feature selection - Linear Regression/RandomForests/Lasso/Correlation plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Regression\n",
    "Due to the size of the dataset we can only really use LinearSVR here, since our dataset is too large to make nonlinear SVR's viable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-eea102e8ac79>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Initial try at SVR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msvm_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLinearSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msvm_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             epsilon=self.epsilon, sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_fit_liblinear\u001b[0;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001b[0m\n\u001b[1;32m    919\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0mclass_weight_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         epsilon, sample_weight)\n\u001b[0m\u001b[1;32m    922\u001b[0m     \u001b[0;31m# Regarding rnd.randint(..) in the above signature:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;31m# seed for srand in range [0..INT_MAX); due to limitations in Numpy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Initial try at SVR\n",
    "svm_reg = LinearSVR(epsilon=0.4, C=0.4, random_state=21)\n",
    "svm_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=LinearSVR(C=1.0, dual=True, epsilon=0.0,\n",
       "                                 fit_intercept=True, intercept_scaling=1.0,\n",
       "                                 loss='epsilon_insensitive', max_iter=1000,\n",
       "                                 random_state=None, tol=0.0001, verbose=0),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.1, 0.4], 'epsilon': [0.2, 0.4]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search SVR\n",
    "parameters = {\n",
    "    'epsilon': [0.2, 0.4],\n",
    "    'C': [0.1, 0.4]\n",
    "}\n",
    "model = LinearSVR()\n",
    "clf = GridSearchCV(model, parameters, scoring='neg_mean_squared_error', cv=3)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_epsilon</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.958821</td>\n",
       "      <td>0.025446</td>\n",
       "      <td>0.009581</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 0.2}</td>\n",
       "      <td>-7.512782</td>\n",
       "      <td>-7.186471</td>\n",
       "      <td>-6.468062</td>\n",
       "      <td>-7.055773</td>\n",
       "      <td>0.436403</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.504628</td>\n",
       "      <td>0.010741</td>\n",
       "      <td>0.009673</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'C': 0.1, 'epsilon': 0.4}</td>\n",
       "      <td>-7.554937</td>\n",
       "      <td>-7.220711</td>\n",
       "      <td>-6.494918</td>\n",
       "      <td>-7.090190</td>\n",
       "      <td>0.442483</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7.982620</td>\n",
       "      <td>0.106887</td>\n",
       "      <td>0.008579</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'C': 0.4, 'epsilon': 0.2}</td>\n",
       "      <td>-7.265266</td>\n",
       "      <td>-6.949928</td>\n",
       "      <td>-6.255557</td>\n",
       "      <td>-6.823585</td>\n",
       "      <td>0.421782</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6.143120</td>\n",
       "      <td>0.100372</td>\n",
       "      <td>0.008617</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>{'C': 0.4, 'epsilon': 0.4}</td>\n",
       "      <td>-7.286887</td>\n",
       "      <td>-6.963951</td>\n",
       "      <td>-6.263851</td>\n",
       "      <td>-6.838230</td>\n",
       "      <td>0.427009</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0       2.958821      0.025446         0.009581        0.000529     0.1   \n",
       "1       2.504628      0.010741         0.009673        0.001280     0.1   \n",
       "2       7.982620      0.106887         0.008579        0.000023     0.4   \n",
       "3       6.143120      0.100372         0.008617        0.000074     0.4   \n",
       "\n",
       "  param_epsilon                      params  split0_test_score  \\\n",
       "0           0.2  {'C': 0.1, 'epsilon': 0.2}          -7.512782   \n",
       "1           0.4  {'C': 0.1, 'epsilon': 0.4}          -7.554937   \n",
       "2           0.2  {'C': 0.4, 'epsilon': 0.2}          -7.265266   \n",
       "3           0.4  {'C': 0.4, 'epsilon': 0.4}          -7.286887   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0          -7.186471          -6.468062        -7.055773        0.436403   \n",
       "1          -7.220711          -6.494918        -7.090190        0.442483   \n",
       "2          -6.949928          -6.255557        -6.823585        0.421782   \n",
       "3          -6.963951          -6.263851        -6.838230        0.427009   \n",
       "\n",
       "   rank_test_score  \n",
       "0                3  \n",
       "1                4  \n",
       "2                1  \n",
       "3                2  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(clf.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.4, 'epsilon': 0.2}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(C=0.4, dual=True, epsilon=0.2, fit_intercept=True,\n",
       "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "          random_state=22, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit model with the best hyper-parameters\n",
    "svm_reg = LinearSVR(epsilon=0.2, C=0.4, random_state=22)\n",
    "svm_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error CV: 6.787131686368653\n"
     ]
    }
   ],
   "source": [
    "#Cross validation scoring metric\n",
    "cv_score = cross_val_score(svm_reg, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(\"Mean Squared Error CV:\", -np.mean(cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.775330130679082\n",
      "6.847785314466136\n"
     ]
    }
   ],
   "source": [
    "preds_train = svm_reg.predict(X_train)\n",
    "preds_test = svm_reg.predict(X_test)\n",
    "print(mean_squared_error(y_train, preds_train))\n",
    "print(mean_squared_error(y_test, preds_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5933483357655558\n",
      "0.5997087616722856\n"
     ]
    }
   ],
   "source": [
    "#Coefficient of determination, R2\n",
    "print(svm_reg.score(X_train, y_train))\n",
    "print(svm_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.21794484, -0.10626046,  6.24359455, ...,  0.02372039,\n",
       "        0.15304131,  0.29812693])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net\n",
    "Elastic Net is a linear regression model that incorporates both l1 and l2 regularisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, fit the model with default hyperparameters, alpha=1, l1_ratio=0.5. We can see that the MSE is much higher than for SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=1, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "           random_state=101, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = ElasticNet(alpha=1, l1_ratio = 0.5, random_state=101)\n",
    "en.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error CV: 16.871055514922304\n"
     ]
    }
   ],
   "source": [
    "#Cross validation scoring metric\n",
    "cv_score_en = cross_val_score(en, X_train, y_train, cv=10, scoring='neg_mean_squared_error')\n",
    "print(\"Mean Squared Error CV:\", -np.mean(cv_score_en))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validated grid search over several potential hyperparameters. The best hyperparameter set found is alpha=0.1, l1_ratio=0.1. l1_ratio being close to zero suggests that the model does not like to suppress any/many features to zero coeff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                                  l1_ratio=0.5, max_iter=1000, normalize=False,\n",
       "                                  positive=False, precompute=False,\n",
       "                                  random_state=None, selection='cyclic',\n",
       "                                  tol=0.0001, warm_start=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'alpha': [0.1, 1, 10],\n",
       "                         'l1_ratio': [0.1, 0.25, 0.5, 0.75, 0.9]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search SVR\n",
    "parameters_en = {\n",
    "    'alpha': [0.1, 1,10],\n",
    "    'l1_ratio': [0.1, 0.25, 0.5, 0.75, 0.9]\n",
    "}\n",
    "eNet = ElasticNet()\n",
    "en_gs = GridSearchCV(eNet, parameters_en, scoring='neg_mean_squared_error', cv=5)\n",
    "en_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1, 'l1_ratio': 0.1}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refit the final model using the best hyperparameter set, gives MSE of 15.35."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNet(alpha=0.1, copy_X=True, fit_intercept=True, l1_ratio=0.1,\n",
       "           max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "           random_state=102, selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en = ElasticNet(alpha=0.1, l1_ratio = 0.1, random_state=102)\n",
    "en.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error CV: 14.682647916765845\n"
     ]
    }
   ],
   "source": [
    "#Cross validation scoring metric\n",
    "cv_score_en = cross_val_score(en, X_train, y_train, cv=10, scoring='neg_mean_squared_error')\n",
    "print(\"Mean Squared Error CV:\", -np.mean(cv_score_en))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
