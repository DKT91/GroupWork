{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage import io, color, exposure, transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import glob\n",
    "import h5py\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, model_from_json\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "NUM_CLASSES = 43\n",
    "IMG_SIZE = 48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_img(img):\n",
    "    # Histogram normalization in y\n",
    "    hsv = color.rgb2hsv(img)\n",
    "    hsv[:,:,2] = exposure.equalize_hist(hsv[:,:,2])\n",
    "    img = color.hsv2rgb(hsv)\n",
    "\n",
    "    # central scrop\n",
    "    min_side = min(img.shape[:-1])\n",
    "    centre = img.shape[0]//2, img.shape[1]//2\n",
    "    img = img[centre[0]-min_side//2:centre[0]+min_side//2,\n",
    "              centre[1]-min_side//2:centre[1]+min_side//2,\n",
    "              :]\n",
    "\n",
    "    # rescale to standard size\n",
    "    img = transform.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    # roll color axis to axis 0\n",
    "#     img = np.rollaxis(img,-1)\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "def get_class(img_path):\n",
    "    return int(img_path.split('/')[-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all training images into a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-bb3aef1951d6>:2: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
      "  with  h5py.File('X2.h5') as hf:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in reading X.h5. Processing all images...\n",
      "Processed 1000/39209\n",
      "Processed 2000/39209\n",
      "Processed 3000/39209\n",
      "Processed 4000/39209\n",
      "Processed 5000/39209\n",
      "Processed 6000/39209\n",
      "Processed 7000/39209\n",
      "Processed 8000/39209\n",
      "Processed 9000/39209\n",
      "Processed 10000/39209\n",
      "Processed 11000/39209\n",
      "Processed 12000/39209\n",
      "Processed 13000/39209\n",
      "Processed 14000/39209\n",
      "Processed 15000/39209\n",
      "Processed 16000/39209\n",
      "Processed 17000/39209\n",
      "Processed 18000/39209\n",
      "Processed 19000/39209\n",
      "Processed 20000/39209\n",
      "Processed 21000/39209\n",
      "Processed 22000/39209\n",
      "Processed 23000/39209\n",
      "Processed 24000/39209\n",
      "Processed 25000/39209\n",
      "Processed 26000/39209\n",
      "Processed 27000/39209\n",
      "Processed 28000/39209\n",
      "Processed 29000/39209\n",
      "Processed 30000/39209\n",
      "Processed 31000/39209\n",
      "Processed 32000/39209\n",
      "Processed 33000/39209\n",
      "Processed 34000/39209\n",
      "Processed 35000/39209\n",
      "Processed 36000/39209\n",
      "Processed 37000/39209\n",
      "Processed 38000/39209\n",
      "Processed 39000/39209\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    with  h5py.File('X2.h5') as hf: \n",
    "        X, Y = hf['imgs'][:], hf['labels'][:]\n",
    "    print(\"Loaded images from X.h5\")\n",
    "    \n",
    "except (IOError,OSError, KeyError):  \n",
    "    print(\"Error in reading X.h5. Processing all images...\")\n",
    "    root_dir = 'GTSRB/Final_Training/Images/'\n",
    "    imgs = []\n",
    "    labels = []\n",
    "\n",
    "    all_img_paths = glob.glob(os.path.join(root_dir, '*/*.ppm'))\n",
    "    np.random.shuffle(all_img_paths)\n",
    "    for img_path in all_img_paths:\n",
    "        try:\n",
    "            img = preprocess_img(io.imread(img_path))\n",
    "            label = get_class(img_path)\n",
    "            imgs.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "            if len(imgs)%1000 == 0: print(\"Processed {}/{}\".format(len(imgs), len(all_img_paths)))\n",
    "        except (IOError, OSError):\n",
    "            print('missed', img_path)\n",
    "            pass\n",
    "\n",
    "    X = np.array(imgs, dtype='float32')\n",
    "    Y = np.eye(NUM_CLASSES, dtype='uint8')[labels]\n",
    "\n",
    "    with h5py.File('X.h5','w') as hf:\n",
    "        hf.create_dataset('imgs', data=X)\n",
    "        hf.create_dataset('labels', data=Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(64, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), padding='same',\n",
    "                     activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = cnn_model()\n",
    "# let's train the model using SGD + momentum (how original).\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr*(0.1**int(epoch/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "test = pd.read_csv('GTSRB/GT-final_test.csv',sep=';')\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "i = 0\n",
    "for file_name, class_id  in zip(list(test['Filename']), list(test['ClassId'])):\n",
    "    img_path = os.path.join('GTSRB/Final_Test/Images/',file_name)\n",
    "    X_test.append(preprocess_img(io.imread(img_path)))\n",
    "    y_test.append(class_id)\n",
    "    \n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12630, 48, 48, 3), (12630,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=False, \n",
    "                            featurewise_std_normalization=False, \n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.2,\n",
    "                            shear_range=0.1,\n",
    "                            rotation_range=10.,)\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31367, 48, 48, 3), (31367, 43), (7842, 48, 48, 3), (7842, 43))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, Y_train.shape, X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinstallise models \n",
    "\n",
    "model = cnn_model()\n",
    "# let's train the model using SGD + momentum (how original).\n",
    "lr = 0.01\n",
    "sgd = SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "          optimizer=sgd,\n",
    "          metrics=['accuracy'])\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    return lr*(0.1**int(epoch/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "980/980 [==============================] - 369s 377ms/step - loss: 0.4204 - accuracy: 0.8670 - val_loss: 0.0783 - val_accuracy: 0.9764\n",
      "Epoch 2/30\n",
      "980/980 [==============================] - 359s 366ms/step - loss: 0.2724 - accuracy: 0.9155 - val_loss: 0.0559 - val_accuracy: 0.9814\n",
      "Epoch 3/30\n",
      "980/980 [==============================] - 287s 293ms/step - loss: 0.2036 - accuracy: 0.9373 - val_loss: 0.0382 - val_accuracy: 0.9884\n",
      "Epoch 4/30\n",
      "980/980 [==============================] - 262s 267ms/step - loss: 0.1646 - accuracy: 0.9498 - val_loss: 0.0366 - val_accuracy: 0.9890\n",
      "Epoch 5/30\n",
      "980/980 [==============================] - 251s 256ms/step - loss: 0.1420 - accuracy: 0.9567 - val_loss: 0.0366 - val_accuracy: 0.9899\n",
      "Epoch 6/30\n",
      "980/980 [==============================] - 446s 455ms/step - loss: 0.1264 - accuracy: 0.9623 - val_loss: 0.0256 - val_accuracy: 0.9918\n",
      "Epoch 7/30\n",
      "980/980 [==============================] - 354s 361ms/step - loss: 0.1238 - accuracy: 0.9639 - val_loss: 0.0245 - val_accuracy: 0.9927\n",
      "Epoch 8/30\n",
      "980/980 [==============================] - 366s 373ms/step - loss: 0.1122 - accuracy: 0.9677 - val_loss: 0.0237 - val_accuracy: 0.9935\n",
      "Epoch 9/30\n",
      "980/980 [==============================] - 384s 392ms/step - loss: 0.1031 - accuracy: 0.9690 - val_loss: 0.0189 - val_accuracy: 0.9940\n",
      "Epoch 10/30\n",
      "980/980 [==============================] - 423s 432ms/step - loss: 0.1106 - accuracy: 0.9674 - val_loss: 0.0193 - val_accuracy: 0.9935\n",
      "Epoch 11/30\n",
      "980/980 [==============================] - 395s 403ms/step - loss: 0.0535 - accuracy: 0.9840 - val_loss: 0.0094 - val_accuracy: 0.9968\n",
      "Epoch 12/30\n",
      "980/980 [==============================] - 477s 487ms/step - loss: 0.0441 - accuracy: 0.9864 - val_loss: 0.0102 - val_accuracy: 0.9973\n",
      "Epoch 13/30\n",
      "980/980 [==============================] - 420s 428ms/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 0.0073 - val_accuracy: 0.9980\n",
      "Epoch 14/30\n",
      "980/980 [==============================] - 437s 446ms/step - loss: 0.0349 - accuracy: 0.9899 - val_loss: 0.0080 - val_accuracy: 0.9976\n",
      "Epoch 15/30\n",
      "980/980 [==============================] - 436s 445ms/step - loss: 0.0330 - accuracy: 0.9901 - val_loss: 0.0080 - val_accuracy: 0.9978\n",
      "Epoch 16/30\n",
      "980/980 [==============================] - 379s 386ms/step - loss: 0.0330 - accuracy: 0.9906 - val_loss: 0.0065 - val_accuracy: 0.9980\n",
      "Epoch 17/30\n",
      "980/980 [==============================] - 390s 398ms/step - loss: 0.0304 - accuracy: 0.9911 - val_loss: 0.0074 - val_accuracy: 0.9976\n",
      "Epoch 18/30\n",
      "980/980 [==============================] - 384s 392ms/step - loss: 0.0309 - accuracy: 0.9919 - val_loss: 0.0062 - val_accuracy: 0.9980\n",
      "Epoch 19/30\n",
      "980/980 [==============================] - 405s 413ms/step - loss: 0.0281 - accuracy: 0.9920 - val_loss: 0.0054 - val_accuracy: 0.9980\n",
      "Epoch 20/30\n",
      "980/980 [==============================] - 398s 406ms/step - loss: 0.0282 - accuracy: 0.9914 - val_loss: 0.0081 - val_accuracy: 0.9983\n",
      "Epoch 21/30\n",
      "980/980 [==============================] - 419s 427ms/step - loss: 0.0245 - accuracy: 0.9925 - val_loss: 0.0072 - val_accuracy: 0.9983\n",
      "Epoch 22/30\n",
      "980/980 [==============================] - 399s 408ms/step - loss: 0.0224 - accuracy: 0.9934 - val_loss: 0.0067 - val_accuracy: 0.9983\n",
      "Epoch 23/30\n",
      "980/980 [==============================] - 441s 450ms/step - loss: 0.0237 - accuracy: 0.9925 - val_loss: 0.0067 - val_accuracy: 0.9982\n",
      "Epoch 24/30\n",
      "980/980 [==============================] - 409s 417ms/step - loss: 0.0226 - accuracy: 0.9931 - val_loss: 0.0067 - val_accuracy: 0.9982\n",
      "Epoch 25/30\n",
      "980/980 [==============================] - 399s 407ms/step - loss: 0.0227 - accuracy: 0.9930 - val_loss: 0.0066 - val_accuracy: 0.9982\n",
      "Epoch 26/30\n",
      "980/980 [==============================] - 395s 403ms/step - loss: 0.0221 - accuracy: 0.9932 - val_loss: 0.0063 - val_accuracy: 0.9980\n",
      "Epoch 27/30\n",
      "980/980 [==============================] - 403s 411ms/step - loss: 0.0215 - accuracy: 0.9935 - val_loss: 0.0065 - val_accuracy: 0.9980\n",
      "Epoch 28/30\n",
      "980/980 [==============================] - 396s 404ms/step - loss: 0.0253 - accuracy: 0.9924 - val_loss: 0.0066 - val_accuracy: 0.9983\n",
      "Epoch 29/30\n",
      "980/980 [==============================] - 421s 430ms/step - loss: 0.0229 - accuracy: 0.9926 - val_loss: 0.0063 - val_accuracy: 0.9982\n",
      "Epoch 30/30\n",
      "980/980 [==============================] - 421s 429ms/step - loss: 0.0229 - accuracy: 0.9931 - val_loss: 0.0060 - val_accuracy: 0.9985\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "nb_epoch = 30\n",
    "\n",
    "history = model.fit(datagen.flow(X_train, \n",
    "                                 Y_train, \n",
    "                                 batch_size=batch_size),\n",
    "                            steps_per_epoch=int(X_train.shape[0]/batch_size),\n",
    "                            epochs=nb_epoch,\n",
    "                            validation_data=(X_val, Y_val),\n",
    "                            callbacks=[LearningRateScheduler(lr_schedule),\n",
    "                                       ModelCheckpoint('model.h5',save_best_only=True)]\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.9844813935075217\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "acc = np.sum(y_pred==y_test)/np.size(y_pred)\n",
    "\n",
    "print(\"Test accuracy = {}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 48, 48, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 46, 46, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 23, 23, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 23, 23, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 21, 21, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10, 10, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 10, 10, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 43)                22059     \n",
      "=================================================================\n",
      "Total params: 1,358,155\n",
      "Trainable params: 1,358,155\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
